# RAG File Structure

```
asktemoc/
â”œâ”€â”€ ingest_stub/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ embed_stub/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ query_stub/
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md  
```

## ğŸ‘¥ Team Structure & Responsibilities

### Person A â€” Ingestion & Parsing (Ingest Team)
- **Web scrapers / document loaders**
- **OCR pipeline** 
- **Chunking strategies**
- **Document metadata management**
- **Raw-document store (SQLite)**

### Person B â€” Embeddings & Vector Store (Index Team)
- **Embedding pipeline**
- **Local vector DB** (Chroma/FAISS for MVP)
- **Vector index schema design**
- **Vector search API**

### Person C â€” Retrieval & LLM Orchestration (RAG/LLM Team)
- **Retrieval logic** (hybrid search for future)
- **Reranker integration**
- **Langchain chains** calling Ollama/remote models
- **Generation & prompt engineering**
- **Chat history management**

### Person D â€” Infra, Evaluation, QA & Dashboard (Ops/Eval Team)
- **CI/CD pipelines**
- **Docker & development environments**
- **OpenAPI/contract testing**
- **RAG evaluation** (DeepEval/RAGAS)
- **Admin dashboard endpoints/CRUD**
- **Deployment documentation**
  

## ğŸ¯ Goal (Person B)

Build a microservice that:

### ğŸ”„ Input Processing
- Takes in text chunks via an API endpoint

### ğŸ¤– Embedding Generation  
- Converts text to embedding vectors using models like:
  - `all-MiniLM-L6-v2` (lightweight, fast)
  - `bge-m3` (multilingual, high performance)

### ğŸ’¾ Vector Storage
- Stores embeddings in local vector databases:
  - **Chroma** (recommended for simplicity)
  - **FAISS** (Facebook's high-performance library)

### ğŸ” Search Capabilities
- Supports similarity search queries
- Returns most relevant text chunks based on query vectors
